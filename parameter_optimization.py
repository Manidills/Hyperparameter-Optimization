# -*- coding: utf-8 -*-
"""Parameter optimization

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MXTXK9XoVStQKk5YmPPxenxwh67ypGIN
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

!git clone https://github.com/krishnaik06/Hyperparameter-Optimization.git

data=pd.read_csv('/content/Hyperparameter-Optimization/Churn_Modelling.csv')

data.head()

data.isnull().sum()

data.info()

corrmat=data.corr()
tf=corrmat.index
plt.figure(figsize=(20,20))
g=sns.heatmap(data[tf].corr(), annot=True)

x=data.iloc[:,3:13]
y=data.iloc[:,13]

x=pd.get_dummies(x, columns=['Geography','Gender'], drop_first=True)

x.head()

params={
    "learning_rate":[0.05,0.5,0.10,0.20,0.30,0.35,0.40],
    "max_depth":[3,4,5,8,9,10,12,15,18,20],
    "min_child_weight":[1,3,5,7],
    "gamma":[0.0,0.1,0.2,0.3,0.4,0.5],
    "colsample_bytree":[0.3,0.5,0.7,0.9,0.11,0.15]
}

from sklearn.model_selection import GridSearchCV,RandomizedSearchCV
import xgboost as xgb

classifier=xgb.XGBClassifier()

random=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=10,verbose=3)

random.fit(x,y)

random.best_estimator_

random.best_params_

classifier=xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
              colsample_bynode=1, colsample_bytree=0.9, gamma=0.1,
              learning_rate=0.35, max_delta_step=0, max_depth=4,
              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,
              nthread=None, objective='binary:logistic', random_state=0,
              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
              silent=None, subsample=1, verbosity=1)

from sklearn.model_selection import cross_val_score

score=cross_val_score(classifier,x,y,cv=10)

score.mean()

from sklearn.model_selection import train_est_split

X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1)

model=classifier.fit(X_train,y_train)

predict=model.predict(X_test)

from sklearn import metrics

print("Accuracy:", metrics.accuracy_score(y_test,predict))

